<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Temporal Sampling for Forgotten Reasoning in LLMs - Fine-tuning models often forget correct solutions, but temporal sampling recovers them without retraining">
  <meta property="og:title" content="Temporal Sampling for Forgotten Reasoning in LLMs"/>
  <meta property="og:description" content="Fine-tuning models often forget correct solutions, but temporal sampling recovers them without retraining"/>
  <meta property="og:url" content="https://temporal-forgetting.github.io/Temporal_Forgetting/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="Temporal Sampling for Forgotten Reasoning in LLMs">
  <meta name="twitter:description" content="Fine-tuning models often forget correct solutions, but temporal sampling recovers them without retraining">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="temporal forgetting, temporal sampling, large language models, reinforcement learning, reasoning, checkpoint sampling">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Temporal Sampling for Forgotten Reasoning in LLMs</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Temporal Sampling for Forgotten Reasoning in LLMs</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://yuetl9.github.io" target="_blank">Yuetai Li</a><sup>1*</sup>,</span>
                <span class="author-block">
                  <a href="https://zhangchenxu.com/" target="_blank">Zhangchen Xu</a><sup>1*</sup>,</span>
                  <span class="author-block">
                    <a href="https://fqjiang.work" target="_blank">Fengqing Jiang</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.ece.uw.edu/people/bhaskar-ramasubramanian/" target="_blank">Bhaskar Ramasubramanian</a><sup>3</sup>,</span>
                  <span class="author-block">
                    <a href="https://luyaoniu.github.io/" target="_blank">Luyao Niu</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://yuchenlin.xyz/" target="_blank">Bill Yuchen Lin</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://xiangyue9607.github.io/" target="_blank">Xiang Yue</a><sup>2â€¡</sup>,</span>
                  <span class="author-block">
                    <a href="https://people.ece.uw.edu/radha/" target="_blank">Radha Poovendran</a><sup>1â€¡</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>University of Washington</span>
                    <span class="author-block"><sup>2</sup>Carnegie Mellon University</span>
                    <span class="author-block"><sup>3</sup>Western Washington University</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution <sup>â€¡</sup>Equal Advising</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2505.20196" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <span class="link-block">
                      <a href="" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon" role="img" aria-label="hugging face">ðŸ¤—</span>
                      <span>Huggingface</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/uw-nsl/Temporal_Forgetting" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2505.20196" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Fine-tuning large language models (LLMs) is intended to improve their reasoning capabilities, yet we uncover a counterintuitive effect: models often forget how to solve problems they previously answered correctly during training. We term this phenomenon <strong>Temporal Forgetting</strong> and show that it is widespread across model sizes, fine-tuning methods (both Reinforcement Learning and Supervised Fine-Tuning), and multiple reasoning benchmarks. Our analysis reveals that 6.4% to 56.1% of final errors were once solved correctly at an earlier checkpoint. 
          </p>
          <p>
            Inspired by the phenomenon of Temporal Forgetting, we proposed <strong>Temporal Sampling</strong>, a simple decoding strategy that draws outputs from multiple checkpoints along the training trajectory. This approach recovers forgotten solutions without retraining or ensembling, and leads to significant improvements in reasoning performance, gains from 4 to 19 points in Pass@k and consistent gains for majority-voting and Best-of-N across several benchmarks. To make Temporal Sampling deployment-friendly, we extend it to LoRA-adapted models. By leveraging the temporal diversity inherent in training, Temporal Sampling offers a practical, compute-efficient way to surface hidden reasoning ability and rethink how we evaluate LLMs.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Temporal Forgetting Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="has-text-centered">
      <h2 class="title is-3">Temporal Forgetting and Temporal Sampling</h2>
    </div>
    <figure class="image" style="max-width: 80%; margin: 2rem auto;">
      <img src="static/images/teaser.jpg" alt="Temporal Forgetting Illustration" />
    </figure>
    <div class="content">
      <p>
        We observed that during RL training process of Deepseek-R1-1.5B model, <strong>76.7% of AIME problems were solved correctly at some intermediate checkpoint</strong>, yet only 30% remained correct in the final model. We term this phenomenon as <strong>Temporal Forgetting</strong>.
      </p>
      <p>
        <strong>Temporal Sampling</strong> utilizes training dynamics as a source of answer diversity by distributing inference samples across multiple distinct checkpoints from the training trajectory, rather than relying solely on the single final checkpoint.
      </p>
    </div>
  </div>
</section>

<!-- Main Takeaways Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="has-text-centered">
      <h2 class="title is-3">Main Takeaways</h2>
    </div>
    
    <!-- Takeaway 1 -->
    <div class="box">
      <h3 class="subtitle is-4">Takeaway 1: Overall Performance Score Cannot Tell Everything</h3>
      <div class="content">
        <p>
          In spite of the improvement of overall performance, a considerable percentage of questions answered correctly by the base model may be answered incorrectly after RL/SFT.
        </p>
        <figure class="image" style="margin: 1rem 0;">
          <img src="static/images/takeaway_1_1.jpg" alt="Overall Performance Analysis">
        </figure>
        <p>
          Fine-tuned models like DeepscaleR-1.5B and OpenR1-7B outperform the base model overall but also forget many questions the base model answered correctly. This highlights that overall performance metrics cannot capture the nuanced changes happening during training.
        </p>
      </div>
    </div>
    
    <!-- Takeaway 2 -->
    <div class="box">
      <h3 class="subtitle is-4">Takeaway 2: Temporal Forgetting</h3>
      <div class="content">
        <p>
          Benchmark questions may oscillate between correct and incorrect states across checkpoints during RL/SFT. A considerable percentage of questions (from 6.4% to 56.1%) are answered correctly at some checkpoint during training but are ultimately incorrect in the final checkpoint.
        </p>
        <figure class="image" style="margin: 1rem 0;">
          <img src="static/images/takeaway_2_1.jpg" alt="Forgetting Dynamics">
        </figure>
        <p>
          Answer correctness trajectories for OlympiadBench questions across training checkpoints, illustrating solutions oscillate between correct and incorrect states. The percentage of questions per benchmark that are ever forgotten or ever correct at some checkpoint during GRPO shows significant temporal dynamics.
        </p>
        <figure class="image" style="margin: 1rem 0;">
          <img src="static/images/takeaway_2_2.jpg" alt="Forgetting Dynamics">
        </figure>
        <p>
          Performance of fine-tuned models (P<sub>FT</sub> â†‘), the Ever Correct Score (P<sub>ECS</sub> â†‘), and the Temporal Forgetting Score (P<sub>TFS</sub> â†“) of different models after GRPO or SFT. We observed both high P<sub>ECS</sub> and P<sub>TFS</sub>, which implies a high percentage of questions (from 6.4\% to 56.1\%) are answered correctly at some checkpoint during training but are ultimately incorrect in the final checkpoint.
        </p>
      </div>
    </div>
    
    <!-- Takeaway 3 -->
    <div class="box">
      <h3 class="subtitle is-4">Takeaway 3: Improvement of Sampling Performance</h3>
      <div class="content">
        <p>
          Temporal Sampling has higher pass rates than sampling only on the final checkpoint.
        </p>
        <figure class="image" style="margin: 1rem 0;">
          <img src="static/images/takeaway_3.jpg" alt="Pass@k Performance">
        </figure>
        <p>
          Pass@k for different numbers of checkpoints t on the AIME2024, AMC, and AIME2025 benchmarks. Our proposed Temporal Sampling for Qwen2.5-7B with t = 8 outperforms the baseline by more than 19, 13, and 4 percentage points on AIME2024, AMC, and AIME2025, respectively, when sampling 64 responses.
        </p>
      </div>
    </div>
    
    <!-- Takeaway 4 -->
    <div class="box">
      <h3 class="subtitle is-4">Takeaway 4: Improvement of Test-Time Scaling Performance</h3>
      <div class="content">
        <p>
          Temporal Sampling has better test-time scaling performance than sampling only on the final checkpoint.
        </p>
        <figure class="image" style="margin: 1rem 0;">
          <img src="static/images/takeaway_4_1.jpg" alt="Majority Voting Performance">
        </figure>
        <figure class="image" style="margin: 1rem 0;">
          <img src="static/images/takeaway_4_2.jpg" alt="Majority Voting Performance">
        </figure>
        <p>
          Maj@k (Majority voting) and Best-of-N results show that Temporal Sampling with t = 8 checkpoints significantly outperforms the baseline across multiple benchmarks. This demonstrates the effectiveness of leveraging temporal diversity for various inference-time scaling approaches.
        </p>
      </div>
    </div>

    <!-- Takeaway 5 -->
    <div class="box">
      <h3 class="subtitle is-4">Takeaway 5: Temporal Sampling with LoRA</h3>
      <div class="content">
        <p>
          Temporal Sampling can be efficiently implemented using LoRA-adapted models, reducing storage requirements while improving performance gains.
        </p>
        <figure class="image" style="margin: 1rem 0;">
          <img src="static/images/takeaway_5.jpg" alt="LoRA Performance">
        </figure>
        <p>
          Performance of Temporal Sampling using 8 checkpoints from LoRA SFT of Qwen2.5-7B. Results demonstrate that Temporal Sampling with LoRA checkpoints surpasses the baseline (sampling only from the final checkpoint) for both Pass@k and Maj@k, making it more storage-efficient for deployment.
        </p>
      </div>
    </div>
    
  </div>
</section>



<!--BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <p>
        If you find our work useful, please consider citing our paper:
      </p>
      <pre><code>
        @article{li2025temporal,
          title={Temporal Sampling for Forgotten Reasoning in LLMs},
          author={Li, Yuetai and Xu, Zhangchen and Jiang, Fengqing and Ramasubramanian, Bhaskar and Niu, Luyao and Lin, Bill Yuchen and Yue, Xiang and Poovendran, Radha},
          journal={arXiv preprint arXiv:2502.12143},
          year={2025}
        }
    </code></pre>
    </div>
</section> -->
<!--End BibTex citation -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>